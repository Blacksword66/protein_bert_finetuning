{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune the model for the signal peptide benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from proteinbert import OutputType, OutputSpec, FinetuningModelGenerator, load_pretrained_model, finetune, evaluate_by_len\n",
    "from proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed = 100\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Benchmark name and output specification\n",
    "BENCHMARK_NAME = 'ProFET_NP_SP_Cleaved'\n",
    "BENCHMARKS_DIR = '/Users/yeyatiprasher/Coding/Internship/protein_bert/protein_benchmarks'\n",
    "OUTPUT_TYPE = OutputType(False, 'binary')\n",
    "UNIQUE_LABELS = [0, 1]\n",
    "OUTPUT_SPEC = OutputSpec(OUTPUT_TYPE, UNIQUE_LABELS)\n",
    "\n",
    "# Directory containing benchmarks\n",
    "\n",
    "# Loading the dataset\n",
    "train_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.train.csv' % BENCHMARK_NAME)\n",
    "train_set = pd.read_csv(train_set_file_path).dropna().drop_duplicates()\n",
    "train_set, valid_set = train_test_split(train_set, stratify=train_set['label'], test_size=0.1, random_state=100)\n",
    "\n",
    "test_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.test.csv' % BENCHMARK_NAME)\n",
    "test_set = pd.read_csv(test_set_file_path).dropna().drop_duplicates()\n",
    "\n",
    "print(f'{len(train_set)} training set records, {len(valid_set)} validation set records, {len(test_set)} test set records.')\n",
    "print(valid_set.head(10))\n",
    "\n",
    "# Loading the pre-trained model and fine-tuning it on the loaded dataset\n",
    "batch_size = 26\n",
    "seq_len = 512\n",
    "final = seq_len * 2\n",
    "pretrained_model_generator, input_encoder = load_pretrained_model()\n",
    "\n",
    "# get_model_with_hidden_layers_as_outputs gives the model output access to the hidden layers (on top of the output)\n",
    "model_generator = FinetuningModelGenerator(pretrained_model_generator, OUTPUT_SPEC, pretraining_model_manipulation_function=get_model_with_hidden_layers_as_outputs, dropout_rate=0.17681099042260753)\n",
    "\n",
    "training_callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=1, factor=0.25, min_lr=1e-05, verbose=1),\n",
    "    keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True),\n",
    "]\n",
    "\n",
    "finetune(model_generator, input_encoder, OUTPUT_SPEC, train_set['seq'], train_set['label'], valid_set['seq'], valid_set['label'],\n",
    "         seq_len=seq_len, batch_size=batch_size, max_epochs_per_stage=1, lr=8.741510119145999e-05, begin_with_frozen_pretrained_layers=True,\n",
    "         lr_with_frozen_pretrained_layers=1e-02, n_final_epochs=1, final_seq_len=final, final_lr=1e-05, callbacks=training_callbacks)\n",
    "\n",
    "    # Evaluating the performance on the test set\n",
    "results, confusion_matrix = evaluate_by_len(model_generator, input_encoder, OUTPUT_SPEC, test_set['seq'], test_set['label'],\n",
    "                                            start_seq_len=seq_len, start_batch_size=batch_size)\n",
    "print(\"seq_len = %d\" % seq_len)\n",
    "print('Test-set performance:')\n",
    "display(results)\n",
    "\n",
    "print('Confusion matrix:')\n",
    "display(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding number of uniquely labeled sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from proteinbert import OutputType, OutputSpec, FinetuningModelGenerator, load_pretrained_model, finetune, evaluate_by_len\n",
    "from proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs\n",
    "\n",
    "BENCHMARKS_DIR = '/Users/yeyatiprasher/Coding/Internship/protein_bert/protein_benchmarks'\n",
    "BENCHMARK_NAME = 'ProFET_NP_SP_Cleaved'\n",
    "OUTPUT_TYPE = OutputType(False, 'binary')\n",
    "UNIQUE_LABELS = [0,1]\n",
    "OUTPUT_SPEC = OutputSpec(OUTPUT_TYPE, UNIQUE_LABELS)\n",
    "\n",
    "train_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.train.csv' % BENCHMARK_NAME)\n",
    "train_set = pd.read_csv(train_set_file_path).dropna().drop_duplicates()\n",
    "#train_set, valid_set = train_test_split(train_set, stratify=train_set['label'], test_size=0.1, random_state=100)\n",
    "\n",
    "test_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.test.csv' % BENCHMARK_NAME)\n",
    "test_set = pd.read_csv(test_set_file_path).dropna().drop_duplicates()\n",
    "\n",
    "\n",
    "print(\"Training Set pos : \", len(train_set[train_set[\"label\"] == 1]))\n",
    "print(\"Training Set neg : \", len(train_set[train_set[\"label\"] == 0]))\n",
    "print(len(train_set))\n",
    "print(\"Testing Set pos : \", len(test_set[test_set[\"label\"] == 1]))\n",
    "print(\"Testing Set neg : \", len(test_set[test_set[\"label\"] == 0]))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from proteinbert import OutputType, OutputSpec, FinetuningModelGenerator, load_pretrained_model, finetune, evaluate_by_len\n",
    "from proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs\n",
    "\n",
    "BENCHMARKS_DIR = '/Users/yeyatiprasher/Coding/Internship/protein_bert/protein_benchmarks'\n",
    "BENCHMARK_NAME = 'scop'\n",
    "OUTPUT_TYPE = OutputType(False, 'categorical')\n",
    "UNIQUE_LABELS = ['a','b','c','d','e','f','g']\n",
    "OUTPUT_SPEC = OutputSpec(OUTPUT_TYPE, UNIQUE_LABELS)\n",
    "\n",
    "train_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.train.csv' % BENCHMARK_NAME)\n",
    "train_set = pd.read_csv(train_set_file_path).dropna().drop_duplicates()\n",
    "train_set, valid_set = train_test_split(train_set, stratify=train_set['label'], test_size=0.1, random_state=100)\n",
    "\n",
    "test_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.test.csv' % BENCHMARK_NAME)\n",
    "test_set = pd.read_csv(test_set_file_path).dropna().drop_duplicates()\n",
    "\n",
    "\n",
    "print(\"Training Set a : \", len(train_set[train_set[\"label\"] == 'a']))\n",
    "print(\"Training Set b : \", len(train_set[train_set[\"label\"] == 'b']))\n",
    "print(\"Training Set c : \", len(train_set[train_set[\"label\"] == 'c']))\n",
    "print(\"Training Set d : \", len(train_set[train_set[\"label\"] == 'd']))\n",
    "print(\"Training Set e : \", len(train_set[train_set[\"label\"] == 'e']))\n",
    "print(\"Training Set f : \", len(train_set[train_set[\"label\"] == 'f']))\n",
    "print(\"Training Set g : \", len(train_set[train_set[\"label\"] == 'g']))\n",
    "print(len(train_set))\n",
    "print(\"Valid Set a : \", len(valid_set[valid_set[\"label\"] == 'a']))\n",
    "print(\"Valid Set b  : \", len(valid_set[valid_set[\"label\"] == 'b']))\n",
    "print(\"Valid Set c : \", len(valid_set[valid_set[\"label\"] == 'c']))\n",
    "print(\"Valid Set d : \", len(valid_set[valid_set[\"label\"] == 'd']))\n",
    "print(\"Valid Set e : \", len(valid_set[valid_set[\"label\"] == 'e']))\n",
    "print(\"Valid Set f : \", len(valid_set[valid_set[\"label\"] == 'f']))\n",
    "print(\"Valid Set g : \", len(valid_set[valid_set[\"label\"] == 'g']))\n",
    "print(len(valid_set))\n",
    "print(\"Testing Set a : \", len(test_set[test_set[\"label\"] == 'a']))\n",
    "print(\"Testing Set b : \", len(test_set[test_set[\"label\"] == 'b']))\n",
    "print(\"Testing Set c : \", len(test_set[test_set[\"label\"] == 'c']))\n",
    "print(\"Testing Set d : \", len(test_set[test_set[\"label\"] == 'd']))\n",
    "print(\"Testing Set e : \", len(test_set[test_set[\"label\"] == 'e']))\n",
    "print(\"Testing Set f : \", len(test_set[test_set[\"label\"] == 'f']))\n",
    "print(\"Testing Set g : \", len(test_set[test_set[\"label\"] == 'g']))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proteinbert import tokenization as tk\n",
    "import pandas as pd\n",
    "import csv\n",
    "train_set_file_path = \"/Users/yeyatiprasher/Coding/Internship/protein_bert/protein_benchmarks/ProFET_NP_SP_Cleaved.train.csv\"\n",
    "train_set = pd.read_csv(train_set_file_path).dropna().drop_duplicates()\n",
    "f = open(\"/Users/yeyatiprasher/Coding/Internship/protein_bert/NPCleaved_embed.csv\",\"w\")\n",
    "writer = csv.writer(f)\n",
    "for i in train_set['seq']:\n",
    "    embed = tk.tokenize_seq(i)\n",
    "    writer.writerow(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proteinbert import tokenization as tk\n",
    "import pandas as pd\n",
    "import csv\n",
    "train_set_file_path = \"/Users/yeyatiprasher/Coding/Internship/protein_bert/protein_benchmarks/scop.train.csv\"\n",
    "train_set = pd.read_csv(train_set_file_path).dropna().drop_duplicates()\n",
    "f = open(\"/Users/yeyatiprasher/Coding/Internship/protein_bert/scop_embed.csv\",\"w\")\n",
    "writer = csv.writer(f)\n",
    "for i in train_set['seq']:\n",
    "    embed = tk.tokenize_seq(i)\n",
    "    writer.writerow(embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import optuna\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from proteinbert import OutputType, OutputSpec, FinetuningModelGenerator, load_pretrained_model, finetune, evaluate_by_len\n",
    "from proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs\n",
    "\n",
    "BENCHMARK_NAME = 'ProFET_NP_SP_Cleaved'\n",
    "BENCHMARKS_DIR = '/Users/yeyatiprasher/Coding/Internship/protein_bert/protein_benchmarks'\n",
    "\n",
    "# A local (non-global) binary output\n",
    "OUTPUT_TYPE = OutputType(False, 'binary')\n",
    "UNIQUE_LABELS = [0, 1]\n",
    "OUTPUT_SPEC = OutputSpec(OUTPUT_TYPE, UNIQUE_LABELS)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the Optuna objective function\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    #batch_size = trial.suggest_int('batch_size', 20, 64)\n",
    "    seed = trial.suggest_int('seed',80,110)\n",
    "    #lr = trial.suggest_loguniform('lr', 1e-5, 1e-3)\n",
    "    #dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    # Loading the dataset\n",
    "    train_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.train.csv' % BENCHMARK_NAME)\n",
    "    train_set = pd.read_csv(train_set_file_path).dropna().drop_duplicates()\n",
    "    train_set, valid_set = train_test_split(train_set, stratify=train_set['label'], test_size=0.1, random_state=seed)\n",
    "\n",
    "    test_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.test.csv' % BENCHMARK_NAME)\n",
    "    test_set = pd.read_csv(test_set_file_path).dropna().drop_duplicates()\n",
    "    print('%d training set records, %d validation set records, %d test set records.' % (len(train_set), len(valid_set), len(test_set)))\n",
    "\n",
    "    pretrained_model_generator, input_encoder = load_pretrained_model()\n",
    "    model_generator = FinetuningModelGenerator(\n",
    "        pretrained_model_generator, OUTPUT_SPEC, \n",
    "        pretraining_model_manipulation_function=get_model_with_hidden_layers_as_outputs,\n",
    "        dropout_rate=0.17681099042260753\n",
    "    )\n",
    "\n",
    "    training_callbacks = [\n",
    "        keras.callbacks.ReduceLROnPlateau(patience=1, factor=0.25, min_lr=1e-05, verbose=1),\n",
    "        keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True),\n",
    "    ]\n",
    "\n",
    "    finetune(model_generator, input_encoder, OUTPUT_SPEC, train_set['seq'], train_set['label'], valid_set['seq'], valid_set['label'], \n",
    "             seq_len=512, batch_size=32, max_epochs_per_stage=1, lr=8.741510119145999e-05, \n",
    "             begin_with_frozen_pretrained_layers=True, lr_with_frozen_pretrained_layers=1e-02, \n",
    "             n_final_epochs=1, final_seq_len=1024, final_lr=1e-05, callbacks=training_callbacks)\n",
    "\n",
    "    results, confusion_matrix = evaluate_by_len(model_generator, input_encoder, OUTPUT_SPEC, test_set['seq'], test_set['label'], \n",
    "                                                start_seq_len=512, start_batch_size=32)\n",
    "    \n",
    "    overall_accuracy = results.loc['All', 'AUC']\n",
    "    print(overall_accuracy)\n",
    "    return overall_accuracy\n",
    "\n",
    "# Create an Optuna study and optimize\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print('Best hyperparameters: ', study.best_params)\n",
    "print('Best accuracy: ', study.best_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
